# 프로젝트명: 봄온 AI 스피치 분석 프로토타입 (Speech Insight Pro)

## 1. 개발 목적 및 배경
- 아나운서/쇼호스트 지망생을 위한 정밀 스피치 분석 도구의 가능성 증명.
- '온라인 영상 피드백' 기능을 중심으로, 지망생들의 공통 실수 데이터를 축적하는 구조 설계.
- 바이브 코딩(Vibe Coding)을 통해 반나절 내에 고퀄리티 프로토타입 구현 및 Vercel 배포.

## 2. 필수 참조 지침
- **중요:** 모든 개발 과정은 프로젝트 루트의 `/VIBE_CODING_GUIDE_2.0` 폴더 내의 지침을 엄격히 준수할 것.
- 코드 구조, 네이밍 컨벤션, UI/UX 철학은 해당 가이드라인에 최적화하여 작성할 것.

## 3. 핵심 기능 요구사항
### A. 멀티모달 입력 시스템
- **웹캠 실시간 녹화:** MediaRecorder API를 사용하여 브라우저에서 직접 영상/음성 녹화 기능 구현.
- **파일 업로드:** 드래그 앤 드롭 방식의 영상 파일 업로드 UI.
- **샘플 시연:** '아나운서 샘플 영상으로 테스트하기' 버튼 (시연용 시나리오 작동).

### B. AI 분석 시뮬레이션 (UX)
- 녹화/업로드 완료 후 'AI 정밀 분석 중...' 애니메이션 노출 (약 3~5초).
- 음성 패턴, 표정 변화, 텍스트 일치도를 분석하고 있다는 시각적 피드백 제공.

### C. 분석 결과 대시보드
- **영상 분석 마커:** 타임라인에 특정 구간(실수 구간) 마킹 및 클릭 시 상세 피드백 팝업.
- **데이터 시각화:** Chart.js를 사용하여 [전문가 음율 vs 나의 음율] 비교 그래프 구현.
- **빅데이터 통계:** "이 구간은 지망생 70%가 자주 틀리는 구간입니다"라는 통계 기반 경고 문구 삽입.

### D. 전환 로직 (CTA)
- 분석 하단에 "전문 강사의 1:1 밀착 교정 예약하기" 버튼 배치.

## 4. 기술 스택 및 디자인
- **Framework:** Vanilla JS (또는 React) + Tailwind CSS (CDN 활용 가능).
- **Library:** Chart.js (그래프), Lucide-react (아이콘).
- **Design:** 전문적이고 신뢰감 있는 Dark Mode, Deep Blue 포인트, 고급스러운 타이포그래피.
- **Deployment:** Vercel 배포를 위한 반응형 레이아웃 최적화.

## 5. 단계별 개발 지침
1. `VIBE_CODING_GUIDE_2.0` 지침에 따라 기본 프로젝트 구조를 설정하라.
2. 메인 UI 레이아웃과 녹화 로직을 먼저 구현하라.
3. 분석 시뮬레이션과 결과 대시보드의 시각화 요소를 완성하라.
4. Vercel 배포 시 오류가 없도록 최종 코드를 정제하라.

## 6. 데이터 기반 성장 관리 및 강사 인사이트 (Education CRM)

### A. 성장 기록 데이터베이스 (Trainee Progress DB)
- **개인별 스택 기록:** 단순히 한 번의 점수가 아니라, 날짜별/차수별 분석 데이터를 누적 저장.
- **강점/약점 매핑:** AI가 각 세션마다 [발성, 발음, 음율, 태도] 점수를 기록하여 개인별 '스피치 레이더 차트' 변화를 추적.
- **극복 로그(Overcome Log):** 이전 세션에서 지적받은 '약점'이 다음 세션에서 얼마나 개선되었는지 수치화 (예: "지난주 대비 조음 정확도 15% 상승").

### B. 강사용 통합 관리 페이지 (Instructor Dashboard)
- **클래스 통계:** 현재 기수 전체가 공통적으로 어려워하는 문장과 발음 패턴 시각화.
- **학생별 정밀 진단:** 강사가 학생의 이름을 클릭하면 그동안 쌓인 모든 분석 리포트와 실제 녹음/영상 데이터를 한눈에 확인.
- **처방전 피드백:** AI 분석 결과 위에 강사가 직접 코멘트를 달아 '최종 처방전'을 발행하는 기능.

### C. 기술적 뼈대 (Tech Skeleton)
- **Supabase 연결:** 모든 분석 결과는 실시간으로 Postgres DB에 적재.
- **데이터 흐름:** [사용자 녹음] -> [AI 분석/점수화] -> [DB 저장] -> [강사/학생 대시보드 시각화].


## 7. 시스템 통합 지침 (System Integration)

- **데이터 연동:** 수강생의 '영상 피드백 결과'와 강사의 '인사이트 대시보드'는 동일한 데이터베이스(Supabase)를 공유한다.
- **자동 업데이트:** 새로운 영상 분석이 완료될 때마다 강사 대시보드의 '전체 통계' 및 '해당 학생의 성장 그래프'가 즉시 갱신되어야 한다.
- **피드백 루프:** 강사가 대시보드에서 남긴 코멘트는 수강생의 결과 화면에 '전문가 처방전'이라는 이름으로 실시간 노출되어야 한다.

## 8. 데이터 연결 및 통계 아키텍처 (Data & Logic Map)

### [단계 1: 데이터 발생 (Student Input)]
1. 수강생이 '영상/음성' 업로드 또는 실시간 녹화 수행.
2. AI가 즉석에서 1차 분석 수행 (발음, 음율, 속도 수치화).
3. **연결:** 분석 결과(JSON)를 Supabase 'Speech_Logs' 테이블에 전송.
   - 저장 데이터: 수강생 ID, 문항 ID, 전체 점수, 구간별 실수 데이터(초 단위), 원본 영상 URL.

### [단계 2: 데이터 가공 (Big Data Processing)]
1. **패턴 분석:** 시스템이 동일한 '문항 ID'를 가진 모든 로그를 전수 조사.
2. **실수 집계:** "A라는 단어에서 실수한 수강생 수 / 전체 연습 수"를 계산.
3. **자동화 로직:** - 실수 빈도가 70%를 넘으면 'High_Risk_Pattern' 테이블에 자동 등록.
   - 이 데이터는 수강생 결과 화면에 "⚠️ 마의 구간" 경고 문구로 즉시 연결됨.

### [단계 3: 데이터 시각화 (Instructor Insight)]
1. **강사 대시보드:** Supabase 'Speech_Logs'와 'High_Risk_Pattern'을 조인(Join)하여 시각화.
2. **통계 정보 연결:**
   - **학급 통계:** "우리 기수 평균 점수 vs 공통 취약 구간 TOP 5".
   - **개인 성장:** 수강생 ID별 '날짜순 점수 변화 그래프' (시계열 데이터 연결).
3. **강사 피드백:** 강사가 대시보드에서 남긴 코멘트가 해당 'Speech_Log'의 'Teacher_Note' 컬럼에 업데이트되어 수강생에게 전달.